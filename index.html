<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="COOLA-LAB">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="COOLA-LAB">
<meta property="article:author" content="COOLA-LAB">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>COOLA-LAB</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">COOLA-LAB</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/21/Pointer-Graph-Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/21/Pointer-Graph-Networks/" itemprop="url">Pointer Graph Networks</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-21T19:00:00+08:00">
                2021-01-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇论文对于现有图神经网络（GNN）处理动态图数据结构能力不足的现状，将Pointer的概念加入到图两点之间，动态地学习图数据结构生成的过程，取得了良好的效果，为之后进一步提高模型泛化能力奠定基础。</p>
<h2 id="1-Background"><a href="#1-Background" class="headerlink" title="1. Background"></a>1. Background</h2><p>GNN在处理静态图结构的问题上表现优异，但如果随着点集规模不断扩大，点之间的关系也随之增加，潜在的图结构也会以指数型递增，对于现有GNN提出了艰巨的挑战。Pointer Graph Networks（PGN）加入pointer的设置，通过pointer学习点与点之间的关系模式，从已知的小规模图结构，推测出整体的图结构。</p>
<h2 id="2-Contributions"><a href="#2-Contributions" class="headerlink" title="2. Contributions"></a>2. Contributions</h2><ul>
<li><p>用神经网络执行的方式来学习和处理基于图结构的算法过程；</p>
</li>
<li><p>利用有监督学习的方法进行潜在图结构的学习和预测；</p>
</li>
<li><p>能够批量生产基于相同拓扑结构的图数据。</p>
</li>
</ul>
<h2 id="3-Main-Idea"><a href="#3-Main-Idea" class="headerlink" title="3. Main Idea"></a>3. Main Idea</h2><h3 id="3-1-Paradigm"><a href="#3-1-Paradigm" class="headerlink" title="3.1 Paradigm"></a>3.1 Paradigm</h3><p>PGN利用了Encoder-Decoder的结构：</p>
<p>输入序列：$\xi^{(1)}$, $\xi^{(2)}$,…,   其中<script type="math/tex">\xi^{(t)} = {\{\vec{e}^{(t)}_1,\vec{e}^{(t)}_2,...,\vec{e}^{(t)}_n\}}</script></p>
<p>$\vec{e}^{(t)}_i$代表了实体$i$在$t$时间步所进行的操作</p>
<p>目标输出：$\vec{y}^{(t)}$是一个0-1的指示方程，表示的是两个点之间的连接状态。</p>
<p>神经网络要完成的目标：成功预测到$t$时间步时，点集所构成的数据结构的连接状态。</p>
<h3 id="3-2-Architecture-of-Networks"><a href="#3-2-Architecture-of-Networks" class="headerlink" title="3.2 Architecture of Networks"></a>3.2 Architecture of Networks</h3><p>本文搭建的神经网络模型如下图所示：</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/1.png" alt="avatar" style="zoom:50%;"></p>
<p>$\vec{z}^{(t)}_i = f( \vec{e}^{(t)}_i,\vec{h}^{(t-1)}_i )\tag{1}$,</p>
<p>其中$f$指的是encoder network，$\vec{z}^{(t)}_i$代表了encoder输出的状态值，$\vec{h}^{(t-1)}_i$代表$t-1$时间步的隐状态.</p>
<p>然后将$Z(t)$输入到一个处理网络Processor P，用于计算下一时刻的隐状态：</p>
<script type="math/tex; mode=display">H(t) = P(Z^{(t)},\Pi^{(t-1)})\tag{2}</script><p>其中$\Pi^{(t-1)}$代表了$t-1$时刻之后点之间的连接状态的groundtruth，可以理解为一个邻接矩阵，矩阵中0值代表两个点没有相连，1代表两个点相连</p>
<p>接着通过读出操作，计算出decoder输出$\vec{y}^{(t)}$：</p>
<script type="math/tex; mode=display">\vec{y}^{(t)} = g(\bigoplus_i\vec{z}^{(t)}_i, \bigoplus_i\vec{h}^{(t)}_i)\tag{3}</script><p>为了更新邻接矩阵$\Pi^{(t)}$，网络利用了attention机制，计算出当前时间步下，实体$i$与其他所有实体之间的相关程度，从而将最相关的点进行相连。</p>
<p>利用一个mask操作$\mu_i^{(t)}$ $\in{0,1}$对$\Pi^{(t)}$进行更新操作，计算每一个点实施的mask值：</p>
<script type="math/tex; mode=display">P(\mu_i)^{(t)} = \psi(\vec{z}^{(t)}_i,\vec{h}^{(t)}_i) \in(0,1)\tag{4}</script><script type="math/tex; mode=display">\mu_i^{(t)} = II{\psi(\vec{z}^{(t)}_i,\vec{h}^{(t)}_i)>0.5}\tag{5}</script><p>其中$II{\psi(\vec{z}^{(t)}_i,\vec{h}^{(t)}_i)&gt;0.5}$表示当$\psi$大于0.5时，整个式子的值为1，否则为0.</p>
<p>基于self-attention计算实体$i$与其他实体$j$之间的相关程度：</p>
<script type="math/tex; mode=display">\vec{q}^{(t)}_i = W_q\vec{h}^{(t)}_i  \quad \vec{k}^{(t)}_i = W_k\vec{h}^{(t)}_i  \quad \vec{\alpha}^{(t)}_{ij} = softmax(<\vec{q}^{(t)}_i ,\vec{k}^{(t)}_i>) \tag{6}</script><p>其中$\vec{\alpha}^{(t)}_{ij}$代表了实体$i$与其他实体$j$之间的相关程度</p>
<p>根据self-attention计算出的$\alpha$,更新监督矩阵$\Pi^{(t)}$：</p>
<script type="math/tex; mode=display">\tilde{\Pi}^{(t)}_{ij} = \mu_i^{(t)}\tilde{\Pi}^{(t-1)}_{ij} + （1-\mu_i^{(t)}）II_{argmax_k(\alpha_{ik}^{(t)})} \quad \Pi^{(t)}_{ij} = \tilde{\Pi}^{(t)}_{ij}\bigvee \tilde{\Pi}^{(t)}_{ji} \tag{7}</script><h3 id="3-2-training-model"><a href="#3-2-training-model" class="headerlink" title="3.2 training model"></a>3.2 training model</h3><p>在神经网络训练的过程中，计算了三种loss，用来进行网络参数的更新，如图所示：</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/2.png" alt="avatar" style="zoom:50%;"></p>
<ul>
<li>$\vec{y}^{(t)}$ against groundtruth $\hat{y}^{(t)}$</li>
<li>$\alpha^{(t)}{ij}$ against groundtruth $\hat{\Pi}^{(t)}_i$</li>
<li>$\Psi$ against modification $\hat{\mu}^{(t)}_i$</li>
</ul>
<h2 id="4-Task"><a href="#4-Task" class="headerlink" title="4. Task"></a>4. Task</h2><p>本文提出神经网络模型主要用于解决动态图的连接问题，基本思路将图定义为Incremental Graph，即图的任意两点之间在刚开始是不存关系的，通过后续的操作将图中的关系补充完整。</p>
<p>下面将通过两个图问题的实例具体解释说明神经网络执行过程：</p>
<h3 id="4-1-Disjoint-set-union"><a href="#4-1-Disjoint-set-union" class="headerlink" title="4.1 Disjoint-set union"></a>4.1 Disjoint-set union</h3><p>并查集主要是用于查询两个元素是否在同一集合中或两者之间是否存在连接关系。init将所有节点的父节点设为自己，find最终返回该元素所在树的根节点，union将两棵树合并成一棵树，如图所示：</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/3.png" alt="avatar" style="zoom:50%;"></p>
<p>PGN处理并查集的时候，对于点的操作就是从以上的三种中进行，通过一个query-union的方法对数据集进行构建：</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/4.png" alt="avatar" style="zoom:50%;"></p>
<h3 id="4-2-Link-Cut-Trees"><a href="#4-2-Link-Cut-Trees" class="headerlink" title="4.2 Link/Cut Trees"></a>4.2 Link/Cut Trees</h3><p>LCTs是一种动态的树结构，用于处理不同树结构节点之间进行转移、切割以及连接的操作。本文神经网络主要用于检查LCTs中两个节点的连接状态。相对应的操作函数有find-root(u), link(u, v), cut(v), evert(u) 。</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/5.png" alt="avatar" style="zoom:50%;"></p>
<p>PGN处理LCTs的时候，对于点的操作就是从以上的函数中进行，通过一个query-toogle的方法对数据集进行构建：</p>
<p><img src="/2021/01/21/Pointer-Graph-Networks/6.png" alt="avatar" style="zoom:50%;"></p>
<h2 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5. Experiment"></a>5. Experiment</h2><p><img src="/2021/01/21/Pointer-Graph-Networks/7.png" alt="avatar" style="zoom:50%;"></p>
<p>通过实验可以看出，随着点集的规模变大，PGN在准确程度方面比传统的GNN有了非常明显的提高。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/" itemprop="url">Decentralized Patrolling Under Constraints in Dynamic Environments</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2021-01-16T15:45:00+08:00">
                2021-01-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <pre><code>作者研究了一个考虑信息与威胁分布的基于动态环境的分散巡逻问题。在这个问题中，代理可以在某个位置获取信息，但同时可能会受到该位置威胁的攻击。每个代理以分散的方式在环境中的指定区域巡逻，并与有限数量的代理进行交互。这些代理的目标是相互协调以收集尽可能多的信息，同时限制所受到的损害。因此，作者将这类问题建模为具有健康约束的部分可观测的马尔可夫决策过程。此外，作者提出了基于蒙特卡罗树搜索和因子置信向量的可伸缩分散在线算法。
本次组会将由该论文展开，简略地讲述如何使用传统的组合优化算法来有效地解决一种具有可分状态及可分价值函数结构特性的复杂强化学习任务。这份简报将按照组会slides的顺序讲述，并为感兴趣的同学补充更多的细节。
</code></pre><h2 id="1-Environments"><a href="#1-Environments" class="headerlink" title="1. Environments"></a>1. Environments</h2><h3 id="1-1-Patrolling-Environments"><a href="#1-1-Patrolling-Environments" class="headerlink" title="1.1 Patrolling Environments"></a>1.1 Patrolling Environments</h3><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt2.PNG" alt="ppt2"></p>
<p>这篇论文将巡逻环境建模为一个<strong>无向图</strong>$G$，并将任务限制在$T$个时间片内。</p>
<p>每个节点$v$有一个状态，其所处的状态可以用两个互相独立的<strong>状态变量</strong>$e_v^R$及$e_v^I$表示。</p>
<p>在这个包含<strong>不确定性</strong>的任务环境下，我们通常<strong>无法确定节点所处的状态</strong>，相反，我们实际使用<strong>信念向量$w_v^R/w_v^I$表示/评估节点处于各个状态概率</strong>。</p>
<p>为了描述环境的动态性，我们假定环境的<strong>状态转移模型</strong>是一个简单的马尔可夫模型，各个节点的两个状态的转移都两两<strong>互相独立</strong>。转移矩阵$P$了描述了某个节点的信息状态/威胁状态在一个转移到另一个状态的概率。</p>
<p>右边给出了一个例子。</p>
<h3 id="1-2-Patrolling-Agents"><a href="#1-2-Patrolling-Agents" class="headerlink" title="1.2 Patrolling Agents"></a>1.2 Patrolling Agents</h3><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt3.PNG" alt="ppt3"></p>
<p>作为完成任务的主体，代理包含有限个成员。</p>
<p>每个代理$A_i$有<strong>其固定的巡逻区域</strong>，每个代理有着<strong>健康约束</strong>，这意味着一个可以正常工作的代理受到的威胁的线性加和不能超过上线$\beta_m$。</p>
<p>每个可以正常工作的代理在每个时间片可以执行的动作是从其所在的节点$v$前往$G$中的相邻节点或是停留在$v$。这个移动不能超出其巡逻范围$g_m$</p>
<p>每个时间片，整个系统获得的收益由<strong>各个代理所处的节点的信息价值共同决定</strong>。函数$\alpha(n)$描述了代理在同一个节点执行任务的合作能力，即$n$个代理能获得收益的比例。通常有：$\alpha(n)$是单调增函数且满足$\lim_{n\rightarrow\infty}\alpha(n)=1，\alpha(0)=0$。</p>
<p>我们定义邻居关系是巡逻区域有重叠的一对代理。一个代理的<strong>邻居集合</strong>由其所有邻居组成。信息<strong>通信仅被允许在邻居间进行</strong>。</p>
<h2 id="2-MCTS"><a href="#2-MCTS" class="headerlink" title="2. MCTS"></a>2. MCTS</h2><p>MCTS是关注少量状态价值的一种有效地在线表格型学习方法。</p>
<p>通过使用<strong>蒙特卡洛模拟</strong>评估关注状态的后续状态价值，并使用<strong>UCB算法</strong>有效地选择需要评估地后续状态。整个过程在一个不平衡的搜索树上完成，因此得名。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt4.PNG" alt="ppt4"></p>
<p>通常，MCT中每个节点代表一个状态$s$,或是由历史轨迹$h$产生的可达状态集$S(h)$。</p>
<p>每个节点至少需要维护节点的访问次数$N$,以及当前的评估价值$Q$。</p>
<p>树上的一条边表示动作或是观察，表示状态在观察或动作后到达一个新的状态集$S(h)$。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt5.PNG" alt="ppt5"></p>
<p>MCTS算法的主要流程包含四个部分：</p>
<ul>
<li><strong>选择</strong>：自顶向下，每次选择UCB值最大的子节点直到一个子节点未完全拓展的节点。</li>
<li><strong>拓展</strong>：选择该节点一个未拓展的子节点进行拓展。</li>
<li><strong>模拟</strong>：通过快速模拟给予拓展节点一个初始状态价值。</li>
<li><strong>反向传播</strong>：使用模拟价值，更新所有前驱状态的价值。</li>
</ul>
<p>通过不断地执行上述四步，最终，各个节点的状态价值会收敛到最优值。</p>
<p>限于篇幅，这里只能简单地介绍。作者建议仍然不了解的读者阅读David的<em>Monte-Carlo Planning in Large POMDPs</em>原文或其他相关材料，以便可以更好地理解后续内容。</p>
<h2 id="3-Main-Idea"><a href="#3-Main-Idea" class="headerlink" title="3. Main Idea"></a>3. Main Idea</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>MCTS的主要瓶颈在于，其要获得足够准确的评估，需要对后续足够多的状态进行评估，而在一个多agent且多阶段的任务中，可能的<strong>后续状态空间过大</strong>，以至于无法实现充足的采样，进而导致评估误差过大。</p>
<p>例如，对于$k$个代理，每个代理动作空间大小为$|A|$，观测空间大小$|O|$,则一步后的可能状态空间大小就有$(|O||A|)^k$,对应于搜索树上就是巨大的分支因子。这对于基于采样的树搜索方法是难以接受的。</p>
<p>本文的<strong>主要技术思路</strong>就是使用<strong>Factored state &amp; Factored value function</strong>来减少后续状态空间的大小，提高节点<strong>可重用性</strong>。</p>
<p>原文中Theorem 1证明了这一问题具有这一性质。</p>
<p>组会slides中给出了更加形式化地证明。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt7.PNG" alt="ppt7"></p>
<p>简而言之，这个性质，就是指<strong>系统总体状态价值$V(h)$可以由局部价值$V_m(h_{K_m})$求和得到。</strong></p>
<p>其中，$h_{K_m}$表示代理$m$的邻居集合的<strong>共同联合历史</strong>。</p>
<p>直观上讲，假设我们为了评估$V(h)$，使用一步后的所有后续状态。我们可能需要枚举共$(|O||A|)^k$的后续状态，以对$h$有一个更好地评估。有了这个性质后，我们可能只需要枚举$\frac{k}{|K_m|}(|O||A|)^{|K_m|}$个状态。</p>
<h2 id="4-Factored-value-function"><a href="#4-Factored-value-function" class="headerlink" title="4. Factored value function"></a>4. Factored value function</h2><p>在一个决策问题中,我们评估状态价值，最终目是要求得一个最优决策即$\arg\max_h V(h)$。如果我们有上述的函数可分性质，同时知道所有的局部子函数$V_m$，该如何快速地求得最优的决策$h$呢？</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt8.PNG" alt="ppt8"></p>
<p>这个问题早有研究，先考虑一个简单的问题：对于满足可分函数性质的函数$F$，求最小的$F(X)$。子函数$f_i(X_i)$仅与两个变量$X_i={x_i,x_{i+1}}$相关。</p>
<p>这个问题可以使用动态规划的方法解决，相较于直接枚举X，复杂度由$O(|A|^M)\rightarrow O(M|A|^2)$。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt9.PNG" alt="ppt9"></p>
<p>一个更加复杂也更加普适的问题：我们不再限制$X_i$仅包含两个变量，而仅需是$X$的子集。</p>
<p>实际上我们也可以采用一种动态规划算法——称为<strong>非序列动态规划或是消元法</strong>（VE）。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt10.PNG" alt="ppt10"></p>
<p>如上，组会slides中展示出了算法运行的一个例子。</p>
<p>大致算法流程如下：</p>
<ol>
<li>选择消元顺序$x_{k_1},x_{k_2},…,x_{k_{n-1}},x_{k_n}$。</li>
<li>找到所有当前消元变量$x_{k_i}$所在的所有函数。</li>
<li>枚举所有函数涉及的所有变量，取最小值消去当前变量$x_{k_i}$计算新的函数。</li>
<li>若仍存在消元变量跳到第二步，否则枚举最后一个函数变量计算最小值。</li>
</ol>
<p>该算法的复杂度取决于所有消元涉及的所有变量的数量/枚举空间的最大值。一个最优的消元顺序可以获得一个最小的上述值，该值等于对应的交互图的induced width。</p>
<p>其复杂度为$O(n|A|^{D(G)})$,$D(G)$是对应的交互图的induced width。</p>
<p>更多细节可以参考论文: Bertele, Umberto, and Francesco Brioschi. “On non-serial dynamic programming.” <em>J. Comb. Theory, Ser. A</em> 14.2 (1973): 137-148.</p>
<h2 id="5-Previous-work"><a href="#5-Previous-work" class="headerlink" title="5. Previous work"></a>5. Previous work</h2><h3 id="5-1-Factored-value-function-amp-RL"><a href="#5-1-Factored-value-function-amp-RL" class="headerlink" title="5.1 Factored value function &amp; RL"></a>5.1 Factored value function &amp; RL</h3><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt11.PNG" alt="ppt11"></p>
<p>很早就有在强化学习中使用这一技术的研究。我们以在Q-learning中的应用为例。上面的组会slides中展示了Q-learning地表格型与近似函数的更新式及对应的Factored value function性质。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt12.PNG" alt="ppt12"></p>
<p>将性质式带入近似函数的Q-learning更新式中，很容易得到新的更新式。</p>
<p>这里，我们希望只需要对局部的$Q_j$建立近似函数，而$Q$则由局部函数组合得到。</p>
<p>这样，类似于我们之前在第三部分最后关于表格型RL的讨论，局部函数的复杂性可以大大降低，因为其输入$x_j,a_j$的维数远远小于$x,a$。</p>
<p>但是涉及到具体更新实现，仍会遇到问题。我们将$V$用$Q$替换以获得更加清晰的更新式：</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt13-1.PNG" alt="ppt13-1"></p>
<p>其中，$Q(x,a,w)$可以由$Q_i(x_i,a_i,w_i)$通过求和计算，$\nabla_{w_i}Q_i(x_i,a_i,w_i)$是我们维护的近似函数，可以直接计算获得。</p>
<p>而实际上，最后的$\max_{a’}Q(x’,a’,w)=\max_{a_i’}\sum Q_i(x’_i,a’_i,w_i)$，与之前第四部分问题形式一致，可以通过VE算法获得。</p>
<p>一个可行的分布式算法流程如下：</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt13-2.PNG" alt="ppt13-2"></p>
<p>可以观察到在这个整体算法流程中我们只需要维护局部Q-value，至于<strong>局部Q-value（或者可以是其他形式的局部状态价值）具体是如何计算更新的并不关心</strong>。这意味着我们可以很自然地使用其他的强化学习算法，甚至不同agent可以使用不同的强化学习算法完成同一个任务。</p>
<p>参考论文：Guestrin, Carlos, Michail Lagoudakis, and Ronald Parr. “Coordinated reinforcement learning.” <em>ICML</em>. Vol. 2. 2002.</p>
<h3 id="5-1-Factored-value-function-amp-MCTS"><a href="#5-1-Factored-value-function-amp-MCTS" class="headerlink" title="5.1 Factored value function &amp; MCTS"></a>5.1 Factored value function &amp; MCTS</h3><p>正如上一部分最后提到的，我们只需要计算局部状态价值。那么是否可以使用MCTS来计算局部价值状态，然后使用相同的协同框架呢？</p>
<p>是可以的。</p>
<p>但是，我们需要考虑到，因为MCTS高效学习的一个关键在于采用了基于全局状态评估的UCB算法，来平衡探索以及挖掘。</p>
<p>实际做法可以很简单：</p>
<p>因为UCB值的形式同Q值类似，可以使用局部状态的UCB值的线性和近似全局的UCB值。</p>
<p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt14.PNG" alt="ppt14"></p>
<p>那么我们同样可以使用VE算法来计算一个最大的UCB值，来进行采样。</p>
<p>在<em>Scalable planning and learning for multiagent POMDPs</em>这篇论文中作者提出了两种使用可分价值函数性质的MCTS算法。</p>
<h4 id="5-1-1-Factored-Statistics"><a href="#5-1-1-Factored-Statistics" class="headerlink" title="5.1.1 Factored Statistics"></a>5.1.1 Factored Statistics</h4><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt15.PNG" alt="ppt15"></p>
<p>算法运行在一棵搜索树上。树的节点表示一个联合的历史轨迹代表的状态集合$S(h)$。</p>
<p>但是，我们不再维护规模巨大的$Q(h,a)$，而是节点上额外维护了<strong>全局状态的局部动作收益$Q_j(h,a_{K_j})$以及$N(h,a_{K_j})$。</strong></p>
<p>通过VE算法，使用局部动作价值计算最大的UCB值。反向传播需要更新全局动作$a$或$o$对应的局部动作价值。其余步骤与原MCTS一致。</p>
<p>由于其仍然是对联合历史轨迹$h$进行的状态评估及采样，不会破坏马尔可夫性质，因此，算法仍然能获得一个有效的收敛。</p>
<p>右边是树结构的一个例子，在slides中还有更加详细的更新步骤实例。</p>
<h4 id="5-1-2-Factored-Tree"><a href="#5-1-2-Factored-Tree" class="headerlink" title="5.1.2 Factored Tree"></a>5.1.2 Factored Tree</h4><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt17.PNG" alt="ppt17"></p>
<p>不同于之前的树结构，Factored Tree使用了多棵搜索树，每棵树的节点代表一个局部的历史轨迹$h_j$。</p>
<p>由于局部的历史轨迹可能不会满足马尔可夫性质，通过局部历史轨迹计算的局部状态价值只能是对于真实局部状态价值的一个估计。这可能会导致结果<strong>不能收敛</strong>，但是可以进一步增大节点的可重用性，减少需要采样的状态空间。</p>
<p>更新式只是将$Q_j(h,a_{K_j})$替换为了$Q_j(h_{K_j},a_{K_j})$。由于$a/o$与边对应，反向传播时与经典的MCTS一致。</p>
<p>右边是树结构的一个例子，在slides中还有更加详细的更新步骤实例。</p>
<p>参考论文：</p>
<p>Christopher Amato and Frans A. Oliehoek. Scalable planning and learning for multiagent POMDPs. InAAAI15, pages 1995–2002, January 2015</p>
<h2 id="6-Main-Contributions"><a href="#6-Main-Contributions" class="headerlink" title="6.Main Contributions"></a>6.Main Contributions</h2><p>回到<em>Decentralized Patrolling Under Constraints in Dynamic Environments</em>这篇论文。</p>
<p>正如我们之前在第三部分所证明的，相较于第五部分的工作，作者考虑的问题模型更加具体，它不仅满足了价值函数可分，同时其局部状态也是可分的，分别如下列左右两式所示：</p>
<script type="math/tex; mode=display">
V(h)=\sum_{A_m\in A}V(h_{K_m})=\sum_{A_m \in A}V_m(h_{K_m})</script><p>所以可以很自然地使用Factored Tree的框架。</p>
<p>基于此，作者主要有三个主要贡献：</p>
<ul>
<li><p>健康约束：</p>
<ul>
<li>将代理的健康状态加入状态考虑中去，并令模拟过程中不满足健康约束的代理强行退出任务，以获得满足健康约束下的最优调度。</li>
<li>对于有限视界内的模拟，使用启发式的健康约束$\hat{b}_m=b_m\frac{\tau(t)}{T-t}$，即估计受到的威胁在整个过程中是平均的。</li>
</ul>
</li>
<li><p>分布式：</p>
<ul>
<li>解决了问题背景中对于代理的通信限制。</li>
<li>使用max-sum算法分布式地实现VE算法的效果。</li>
</ul>
</li>
<li><p>基于可分信念状态的粒子滤波：</p>
<ul>
<li><p>由于状态是可分的，局部的环境可以基于局部的状态及动作，即:</p>
<p>  <img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt20.PNG" alt="ppt20"></p>
</li>
</ul>
</li>
</ul>
<h3 id="6-1-Max-sum"><a href="#6-1-Max-sum" class="headerlink" title="6.1 Max-sum"></a>6.1 Max-sum</h3><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt20-2.PNG" alt="ppt20-2"></p>
<p>Max-sum是VE算法的一种分布式的替代方案。</p>
<p>如右图所示，$x_i$表示变量，$U_i$表示函数。</p>
<p>在每一轮的迭代中，变量节点$i$会为每一个交互的函数节点$j$计算函数$q_{i\rightarrow j(x_i)}$，函数节点$i$会为每一个交互的函数节点$j$计算函数$r_{i\rightarrow j(x_j)}$。</p>
<p>通常，在分布式环境中，决策变量节点的计算任务交由对应决策的代理。函数节点的计算任务交由固定的某一个存在交互的代理。</p>
<p>已经证明在一个无环图中，经过有限次迭代可以收敛。当环的数量为一时，收敛性也具有保证。大量实验表明，在一般图中的收敛结果良好。</p>
<p>参考论文：Delle Fave, Francesco Maria, et al. “A methodology for deploying the max-sum algorithm and a case study on unmanned aerial vehicles.” (2012): 2275-2280.</p>
<h2 id="Empirical-Evaluation"><a href="#Empirical-Evaluation" class="headerlink" title="Empirical Evaluation"></a>Empirical Evaluation</h2><p><img src="/2021/01/16/Decentralized-Patrolling-Under-Constraints-in-Dynamic-Environments/ppt21.PNG" alt="ppt21"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/18/Learning-based-Video-Motion-Magnification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/18/Learning-based-Video-Motion-Magnification/" itemprop="url">Learning-based Video Motion Magnification</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-18T15:22:27+08:00">
                2020-12-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇论文首次提出了基于深度学习的欧拉视频放大方法</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>运动放大（motion magnification）是指在视频中的对应位置，找到时间段内的运动矢量进行放大，然后再权值叠加回去。因为自然界或生活中有很多不易被肉眼察觉的微小运动，比如生物皮肤的变化，微风中轻微摇晃的建筑物等，这些微小变化只有通过运动放大才能直接被肉眼捕捉从而更好地做后续的视频视觉任务。</p>
<p>运动放大问题一直有两种视角来看待，一种是拉格朗日视角，一种是欧拉视角，近年来的工作都是欧拉视角的。拉格朗日视角方法是在视频中跟踪和操纵每一个感兴趣的像素的运动，从而放大视频中物体的运动，这种方法简洁易懂但比较复杂，计算量大且耗时长；而欧拉视角的方法不是去跟踪粒子的运动，而是观察视频中每一个固定像素或者区域的变化，因为物体的运动会导致每一个牵涉到的像素点的内容都在随时变化，所以通过学习并放大这种变化就可以跟踪到物体的运动并实现视频运动放大。</p>
<h2 id="2-Previous-work"><a href="#2-Previous-work" class="headerlink" title="2. Previous work"></a>2. Previous work</h2><p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/1.png" style="zoom: 67%;"></p>
<p>欧拉视频放大的基本流程和框架如图所示，主要分为三个步骤：首先，对视频序列进行空间上的金字塔分解，得到多尺度的边缘及形状特征；其次，对每个尺度的特征都进行相同的、像素级别的、时间上的带通滤波，即对每个像素时间上的信号序列进行频域变换，然后再在频域上选出感兴趣的运动信号的频率范围，增强感兴趣的信号，过滤掉不感兴趣的信号，将矢量放大后的运动信号叠加回滤波前的特征；最后，将放大后的信号再反傅里叶变换回时域空间，金字塔重构融合后得到放大后的视频。</p>
<h2 id="3-First-order-motion-amp-Bounds"><a href="#3-First-order-motion-amp-Bounds" class="headerlink" title="3 First-order motion &amp; Bounds"></a>3 First-order motion &amp; Bounds</h2><p>像素强度intensity为</p>
<script type="math/tex; mode=display">
I(x,t)=f(x+\delta(t)), I(x,0)=f(x)</script><p>其中，$ I(x,t) $是t时刻x位置的图像强度，$ \delta $为位移场，$ \delta(t) $表示t时刻该位置相对于0时刻的位移，$ \alpha $是放大因子</p>
<p>理想的运动放大结果为</p>
<script type="math/tex; mode=display">
\hat{I}(x,t)=f(x+(1+\alpha)\delta(t))</script><p>对$ I(x,t) $进行一阶泰勒展开得到</p>
<script type="math/tex; mode=display">
I(x,t)\approx f(x)+\delta(t)\frac{\partial f(x)}{\partial x}</script><p>通过泰勒展开可以看到x方向的移动会导致被观察的像素点的亮度发生变化，而这种亮度的变化速度和信号在x方向的运动速度之间存在直接的关系，令</p>
<script type="math/tex; mode=display">
B(x,t)=\delta(t)\frac{\partial f(x)}{\partial x}</script><p>则近似的运动放大结果为</p>
<script type="math/tex; mode=display">
\tilde{I}(x,t)=I(x,t)+\alpha B(x,t)
\approx f(x)+(1+\alpha)\delta(t)\frac{\partial f(x)}{\partial x}
\approx f(x+(1+\alpha)\delta(t))</script><p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/2.png" style="zoom: 50%;"></p>
<p>假设$ f(x)=cos(wx) $，令$ \tilde{I}(x,t)\approx \hat{I}(x,t) $，得到约束条件</p>
<script type="math/tex; mode=display">
(1+\alpha)\delta(t)<\frac{\lambda}{8}</script><p>不同放大系数和频率条件下的放大情况如下图所示。</p>
<p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/3.png" style="zoom: 50%;"></p>
<h2 id="4-Main-idea"><a href="#4-Main-idea" class="headerlink" title="4 Main idea"></a>4 Main idea</h2><p>基于深度学习的方法的网络框架如下图所示，网络输入为前后两帧图像$ X_a $和$ X_b $，输出放大图像，网络由编码器、调制器、解码器组成。编码器分离出了图像的纹理特征V和形状特征M，其中形状特征是需要被放大的特征，而纹理特征主要用于作为损失函数的约束，约束放大导致的噪声。并且为了区分纹理和形状特征，在$ X_b $上加随机扰动形成$ X^{‘}_b $帧</p>
<p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/4.png" style="zoom:67%;"></p>
<p>损失函数为</p>
<script type="math/tex; mode=display">
L=L_1(Y,\hat{Y})+\lambda(L_1(V_a,V_b)+L_1(V^{'}_b,V^{'}_Y)+L_1(M_b,M^{'}_b))</script><h2 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5 Experiments"></a>5 Experiments</h2><p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/5.png" style="zoom: 50%;"></p>
<p><img src="/2020/12/18/Learning-based-Video-Motion-Magnification/6.png" alt="6" style="zoom:50%;"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/" itemprop="url">Multi-Robot Coordination for Estimation and Coverage of Unknown Spatial Fields</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-12-03T21:45:24+08:00">
                2020-12-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇文章利用高斯过程来估计未知的标量场并同时联合优化机器人集群的最优覆盖，并且在理论上证明了该算法的no-regret性。</p>
<h2 id="1-问题背景"><a href="#1-问题背景" class="headerlink" title="1.问题背景"></a>1.问题背景</h2><p><img src="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/voronoi.png" style="zoom:80%;" align="center"><br>考虑机器人集群的规模为$n$,让该集群针对一个未知的源或者事件进行最优覆盖，每个机器人的管辖区域是基于Voronoi Partition的，即：</p>
<script type="math/tex; mode=display">
V_i=\left \{q\in \mathbb{R}^2:\forall j\neq i \quad \left \| q-x_i\right \|_2\leqslant \left \| q-x_j\right \|_2\right \}</script><p>该$V_i$就是机器人$x_i$的管辖区域，也叫Voronoi cell.但是机器人在监测自己周围环境的时候，监测性能会与其到监测点之间的距离成反比，因而可以定义Locational Cost为：</p>
<script type="math/tex; mode=display">
l(\phi,x)=\sum_{i=1}^{n}\int _{q\in V_i}\left \| q-x_i\right \|_2^2\phi(q)dq</script><p>为了使Locational Cost最小，可以让机器人处于其管辖区域的重心位置上，即：</p>
<script type="math/tex; mode=display">
c_i(\phi)=\frac{1}{\int _{V_i}\phi(q)dq}\int _{V_i}q\phi(q)dq</script><p>但是该问题背景下，真实的$\phi$是未知的，只能利用集群已经采集到的数据来不断地估计$\phi^{(t)}$,这样便可以将集群部署到最优的位置上。机器人在所处位置上采集到的数据符合下面的模型：</p>
<script type="math/tex; mode=display">
y=\phi(x_i)+\varepsilon</script><p>即采集到的数据是真实数据再加上一定的噪声，这个噪声是服从高斯分布的。</p>
<h2 id="2-算法设计"><a href="#2-算法设计" class="headerlink" title="2.算法设计"></a>2.算法设计</h2><p>本文利用高斯过程来估计density function，一个高斯过程由其均值函数和核函数唯一确定，为了更好的估计，本文为均值函数和核函数均引入了可调节的超参数,再利用极大似然估计法来更新这两个超参数，即：</p>
<script type="math/tex; mode=display">
(\rho ^{(t)},\tau ^{(t)})=argmin_{\rho,\tau}p(y^{(1:t)}|x^{(1:t)};\rho;\tau)</script><p>其中，$x^{(1:t)}$是所有机器人在$t$时刻行走过的路径点，$y^{(1:t)}$则是相应的观测值，$\rho,\tau$分别是该高斯过程中均值函数和景象基函数的超参数也是待优化变量。该优化问题的求解可以使用传统的梯度下降法。<br>当确定了$t$时刻的超参数，便可以利用高斯过程对平面上任一一点的信号强度值进行估计，并平面上每一点的信号强度值也属于一个高斯分布，其均值为：</p>
<script type="math/tex; mode=display">
u^{(t)}(x)=u(x;\rho^{(t)})+k(x;x^{(1:t)})^T(K_{x^{(1:t)}}(\tau^{(t)})+\sigma^2I)^{-1
}(y^{(1:t)}-u^{(1:t)}(\rho^{(t)}))</script><p>方差为：</p>
<script type="math/tex; mode=display">
\sigma(t)=k(x,x,\tau^{(t)})-k(x,x^{(1:t)},\tau^{(t)})^T(K_{x^{(1:t)}}(\tau^{(t)})+\sigma^2I)^{-1
}k(x,x^{(1:t)},\tau^{(t)})</script><p>有了均值和方差后，就可以利用生成相应的代理函数值，传统的GP-UCB算法取置信上界作为代理函数值，而本文采用置信下界作为代理函数值，正因为这个小的改动，却能为理论上的no-regret证明提供了支撑。代理函数的计算如下：</p>
<script type="math/tex; mode=display">
\phi^{(t)}=u^{(t-1)}(q)-\sqrt{\beta ^{(t)}}\sigma^{(t-1)}(q)</script><p>其中$\beta ^{(t)}$是在$\delta$置信度下的一个bound，具体为：</p>
<script type="math/tex; mode=display">
\beta^{(t)}=2log(|D|t^2\frac{\pi ^2}{6\delta})</script><p>基于以上的原则，该算法的具体流程如下：<br><img src="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/algorithm.png" style="zoom:90%;"></p>
<h2 id="3-理论分析"><a href="#3-理论分析" class="headerlink" title="3.理论分析"></a>3.理论分析</h2><p>定义regret为：</p>
<script type="math/tex; mode=display">
r^{(t)}=l(\phi,x^{(t)})-min_xl(\phi,x)\geqslant 0</script><p>其含义就是值$t$时刻机器人集群所处位置造成的Locational Cost和最优部署之间的差值。所以要证明的是累计误差是次线性的，即：</p>
<script type="math/tex; mode=display">
lim_{T\rightarrow \infty }\frac{R_T}{T}=0</script><p>本文构造了一个非常重要的不等式为：</p>
<script type="math/tex; mode=display">
l(\phi^{(t),x^{(t)}})\leqslant l(\phi^{(t)},x^*)\leqslant l(\phi,x^*)</script><p>其中$x^*$是指假设$\phi$下的最优位置部署，不等式中的第二项很关键，因为本文采用了置信下界作为代理函数的值，所以不等式成立，而第一项是指$t$时刻估计的$\phi^{(t)}$的前提下的最优部署，故等式成立，之后再通过证明density function利用已获得数据后不确定性减少是有上下界的，而其中上界是此线性，下界又包含在$r_t^2$中，最后再利用柯西不等式证明了该算法的no-regret性。</p>
<h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4.实验结果"></a>4.实验结果</h2><p>本文分别在真实机器和仿真环境上进行了实验，效果如下所示：<br><img src="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/exp1.png" style="zoom:80%;"><br><img src="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/exp2.png" style="zoom:80%;"><br>同时也追踪了该算法在不同时刻下的Locational Cost的大小,结果如下所示：<br><img src="/2020/12/03/Multi-Robot-Coordination-for-Estimation-and-Coverage-of-Unknown-Spatial-Fields/exp3.png" style="zoom:80%;"><br>可以看出该算法在性能上比GP_UCB算法稍差，但是他为该算法的性能提供了理论上的证明保证。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/" itemprop="url">Collaborated Tasks-driven Mobile Charging and Scheduling: A Near Optimal Result</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-26T21:45:49+08:00">
                2020-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇论文从任务角度考虑无线传感器网络中的移动充电调度问题，提出一个(1-1/e)4的近似算法。</p>
<h2 id="1-Background"><a href="#1-Background" class="headerlink" title="1. Background"></a>1. Background</h2><p>传感器网络是由部署在特定区域内用于完成感知、采集、计算等一系列传感器节点组成。由于传感器节点的电池容量优先，所以需要定期给传感器充电。传统的方法要么是使用不灵活的静态设备进行充电，要么研究工作只关注移动充电的模式（距离、角度等）或者充电的指标（传输率、延迟等），很少从任务角度来考虑充电调度，导致最终的充电效果不佳。</p>
<p>因此这篇论文从任务级考虑传感器的充电需求，具体的问题场景如下图所示。</p>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/scenario.gif"></p>
<p>在一个区域内，存在一些传感器节点和任务节点，一个传感器可参与多个任务的执行，一个任务也可能同时需要多个传感器协作执行。这篇论文采用移动充电小车给传感器充电，由于小车所携带的能量有限，因此只能挑选一些“重要传感器节点”进行充电，小车从起始位置出发，沿着规划的充电路径，并在完成充电任务后回到源点。</p>
<h2 id="2-System-model-amp-Problem-formulation"><a href="#2-System-model-amp-Problem-formulation" class="headerlink" title="2. System model &amp; Problem formulation"></a>2. System model &amp; Problem formulation</h2><h3 id="System-model"><a href="#System-model" class="headerlink" title="System model"></a>System model</h3><ul>
<li><p>能耗模型</p>
<p>  这篇论文将问题场景中的总能耗分成两个方面：充电小车用于路径的能耗和用于传感器充电的能耗。</p>
<script type="math/tex; mode=display">
  C(X)=\sum_{d\in L^{T\mathrm{S}P}(X)}\alpha \cdot d +\sum_{v_{j}\in X}\beta\cdot(e_{j}-e_{j}^{r})</script><p>  其中$\alpha$表示一个长度单位的能耗，$\beta$表示给传感器充一个单位的能量需要充电小车传输$\beta$个单位能量，$d$是小车路径长度，$e_j-e^r_j$是传感器所需的充电能量。</p>
</li>
<li><p>任务效益模型</p>
<p>  这篇论文定义了传感器对于任务的效益模型：</p>
<script type="math/tex; mode=display">
  u(t_{i},\ v_{j})=w_{ij}p_{ij}</script><p>  $w_{ij}$表示传感器$v_j$和任务$t_i$之间的权值，$p_{ij}$表示$v_j$对$t_i$的能量分配策略。</p>
<p>  此外，每个任务存在一个效益上限$U_i$，所以对于任务$t_i$在传感器集合$X$内的总效益表示为：</p>
<script type="math/tex; mode=display">
  U(X,\displaystyle \ t_{i})=\min\{u_{X}({\it t_i}), U_{i}\}</script><p>  因此，这个传感器网络中的任务总效益为：</p>
<script type="math/tex; mode=display">
  U\left(X,\displaystyle \ P\right)=\sum_{i=1}^{n}U\left(X,\ t_{i}\right)=\sum_{i=1}^{n}\min\left\{u_{X}\left({\it t_i}\right), U_{i}\right\}</script><p>  其中矩阵$P$中的元素表示传感器对于每个任务的分配策略。</p>
</li>
</ul>
<h3 id="Problem-formulation"><a href="#Problem-formulation" class="headerlink" title="Problem formulation"></a>Problem formulation</h3><p>通过上面的定义，最后将问题建模成<strong>CTMC</strong>问题如下形式：</p>
<script type="math/tex; mode=display">
\begin{array}{ll}{\text {  Max }} & {U(X, P)} \\ {\text { s.t. }} & {e_{j}-\sum_{t_{1} \in T} p_{i j} h_{j} \geq 0, \quad \forall v_{j} \in V} \\ { } & {\mathcal{C}(X) \leq E, \quad \forall X \subseteq V}\end{array}</script><p>该问题可分成两个子问题考虑：”Budget maximum coverage problem” 和 “Traveling salesman problem”，根据已有研究表明，这两个子问题都是NP-hard，因此原问题也是一个NP-hard问题。</p>
<h2 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3. Approach"></a>3. Approach</h2><p>这篇论文通过构造一个替代函数 $H(X)$ 来近似原目标函数U(X,P)，具体定义如下：</p>
<script type="math/tex; mode=display">
H_{X}(t_{i})=U(X,t_{i}) \\
H(X)=U(X,P^{'})</script><p>其中$P^{‘}$表示近似的能量分配策略，具体的策略是采用贪心思想：对于每一个传感器，将能量按照权重$w_{ij}$比例分配给对应的任务。</p>
<p>因为原问题还涉及到充电小车的路径规划问题可规约到经典的TSP问题，所以这里又采用了最邻近算法<a href="https://link.springer.com/chapter/10.1007%2F978-1-4020-9688-4_3" target="_blank" rel="noopener"><sup>1</sup></a>来近似最优解，即用$\hat C(X)$近似$C(X)$。</p>
<p>根据证明可发现，函数$H(X)$满足子模函数的性质，同时也具有非负性和单调性。因此这篇论文根据2016年的相关工作<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11911" target="_blank" rel="noopener"><sup>2</sup></a>基础，采用贪心的近似算法，具体的算法如下：</p>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/RC.gif" alt></p>
<p>RC-ratio贪心思想主要体现在每次选择的传感器节点都是当前使 <script type="math/tex">\frac {H(X_{j-1} \cup \{v\})-H(X_{j-1})}{\hat C(X_{j-1} \cup \{v\})-\hat C(X_{j-1})}</script> 值最大的那个节点。</p>
<h2 id="4-Theoretical-analysis"><a href="#4-Theoretical-analysis" class="headerlink" title="4. Theoretical analysis"></a>4. Theoretical analysis</h2><p>对于替代函数$H(X)=U(X,P^{‘})$可以证明出是最优解$U(X,P)$的1/2。具体证明过程如图中的例子所示。</p>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/example.gif" alt></p>
<p>而算法RC-ratio已经在[2]中被证明是存在一个(1-1/e)/2的近似，因此乘上函数$H(X)$的近似，最终的算法得到(1-1/e)/4的近似比。</p>
<h2 id="5-Evaluation-amp-Experiment"><a href="#5-Evaluation-amp-Experiment" class="headerlink" title="5. Evaluation &amp; Experiment"></a>5. Evaluation &amp; Experiment</h2><h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/overall task utility.gif"><br><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/energy utilization efficience.gif"></p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><ul>
<li><p>Indoor</p>
<p>  <img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/Indoor office room.gif" alt></p>
</li>
</ul>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/Overall task utility for indoor scenario.gif" alt="Overall task utility for indoor scenario" style="zoom:50%;"></p>
<ul>
<li>Outdoor</li>
</ul>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/Outdoor soccer field.gif" alt></p>
<p><img src="/2020/11/26/Collaborated-Tasks-driven-Mobile-Charging-and-Scheduling-A-Near-Optimal-Result/Overall task utility for outdoor scenario.gif" alt="Overall task utility for outdoor scenario" style="zoom:50%;"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li>[1] <a href="https://link.springer.com/chapter/10.1007%2F978-1-4020-9688-4_3" target="_blank" rel="noopener">D. J. Rosenkrantz et al., “An analysis of several heuristics for the traveling salesman problem,” in Fundamental       Problems in Computing.Springer, 2009, pp. 45–69</a>.</li>
<li>[2] <a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11911" target="_blank" rel="noopener">H. Zhang et al., “Submodular optimization with routing constraints.” in AAAI, vol. 16, 2016, pp. 819–826.</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/11/RouteNet-Leveraging-Graph-Neural-Networks-for-Network-Modeling-and-Optimization-in-SDN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/11/RouteNet-Leveraging-Graph-Neural-Networks-for-Network-Modeling-and-Optimization-in-SDN/" itemprop="url">RouteNet: Leveraging Graph Neural Networks for Network Modeling and Optimization in SDN </a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-11-11T08:43:27+08:00">
                2020-11-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇论文提出了一种叫做RouteNet的方法，这是一种基于MPNN的新型网络模型，用于预测某种场景下的网络的特征矩阵，该模型能够了解拓扑，路由和输入流量之间的复杂关系，从而可以准确估算每个源/目标每个数据包的KPI指标。</p>
<h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><h3 id="一些相关概念"><a href="#一些相关概念" class="headerlink" title="一些相关概念"></a>一些相关概念</h3><ul>
<li>KPI—(Key performance Indicator)<ul>
<li>时延（packet发送和接受的时间差），抖动（相邻packet时延的差值），丢包率（一段时间内丢失的packet比例）等一些描述网络性能的指标，具体可以由一个邻接矩阵矩阵来表示每个节点对之间的一段时间内的平均表现。</li>
</ul>
</li>
<li>网络优化—(Network optimization)<ul>
<li>进行一系列操作使得网络的性能提升</li>
<li>网络优化可以分为两部分循环迭代：1）通过网络模型获取量化的网络性能指标，2）将量化的指标输入优化器获得结果</li>
</ul>
</li>
<li>网络模型—(Network modeling)<ul>
<li>网络优化首先要能度量网络的性能（“<em>we can only optimize what we can model.</em> ”），网络模型就是负责量化网络的目前性能</li>
<li>主流的做法有两个：数学模型（主要是基于排队论的基础—特点是精度低但是速度快）、仿真器（能获得精确的结果，但是仿真速度比较慢）</li>
</ul>
</li>
</ul>
<p>在SDN网络结构中<img src="/2020/11/11/RouteNet-Leveraging-Graph-Neural-Networks-for-Network-Modeling-and-Optimization-in-SDN/image-20201110220025370.png" alt="image-20201110220025370">，如图所示可以实时获取全局的网络信息，从而进行优化，以达到相应的优化目标，左边部分为数据面板，右边部分为控制面板，整个网络优化的过程就可以部署在控制面板中。</p>
<h3 id="本文主要解决问题"><a href="#本文主要解决问题" class="headerlink" title="本文主要解决问题"></a>本文主要解决问题</h3><p>文章主要是利用MPNN的思想建立了一个监督学习的神经网络用来预测网络的KPI指标，监督的样本来自仿真器的Ground-Truth，最后训练出来的模型具有应对类似拓扑的泛化能力以及实验证明可靠的精度。</p>
<p>换言之，主要就是用AI代替了传统网络优化过程中的网络KPI量化这一步骤。</p>
<h2 id="2-主要思想"><a href="#2-主要思想" class="headerlink" title="2. 主要思想"></a>2. 主要思想</h2><h3 id="MPNN-Message-Passing-Neural-Network-—通用GCN框架"><a href="#MPNN-Message-Passing-Neural-Network-—通用GCN框架" class="headerlink" title="MPNN(Message-Passing Neural Network)—通用GCN框架"></a>MPNN(Message-Passing Neural Network)—通用GCN框架</h3><p>文章作者表示，方法的主要思想起源于MPNN（Gilmer J, Schoenholz S S, Riley P F, et al. Neural message passing for quantum chemistry[J]. arXiv preprint arXiv:1704.01212, 2017.），这篇文章里主要概括了之前的主要GCN模型，并抽象出一个普适的GCN框架，这个框架将GCN网络分为三部分：</p>
<ol>
<li>Message Passing</li>
<li>State Update</li>
<li>Readout</li>
</ol>
<p>这边结合之前张凯学长的一篇<a href="https://coola-lab.github.io/2020/09/20/Inductive-Representation-Learning-on-Large-Graphs/" target="_blank" rel="noopener">组会报告</a>来解释这个框架，这篇报告的文章提出了一个GraphSAGE的方法，算法过程如下：<img src="/2020/11/11/RouteNet-Leveraging-Graph-Neural-Networks-for-Network-Modeling-and-Optimization-in-SDN/image-20201110224404481.png" alt></p>
<p>算法过程中标出的部分即为三个MPNN的三个步骤。</p>
<p>GCN的贡献就在于能提取出传统网络的拓扑信息，然后进行接下来的分类回归等操作。</p>
<h3 id="RouteNet"><a href="#RouteNet" class="headerlink" title="RouteNet"></a>RouteNet</h3><p>一个packet传输经过若干条链路，所有链路的集合称之为路径，作者的模型基于以下的原则：</p>
<ol>
<li>每个路径的状态取决于所有链路的状态</li>
<li>一个链路的状态取决于所有经过这条链路的路径的状态</li>
</ol>
<h2 id="3-方法"><a href="#3-方法" class="headerlink" title="3. 方法"></a>3. 方法</h2><p>算法过程如下图所示：<img src="/2020/11/11/RouteNet-Leveraging-Graph-Neural-Networks-for-Network-Modeling-and-Optimization-in-SDN/image-20201110231404662.png" alt="image-20201110231404662"></p>
<p>首先初始化路径和各个链路的初始状态，接着对每个链路和路径进行Message Passing 操作，最后再进行readout操作，通过反向传播进行学习。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/" itemprop="url">SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-10-26T20:46:34+08:00">
                2020-10-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文通过分析和比较各类跟踪器在目标状态估计任务上的表现，做出两项主要贡献：提出一套高性能通用跟踪器的设计要点；根据要点设计出SiamFC++跟踪器，同时证明设计要点的有效性。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>跟踪任务可以被分解为分类任务和状态估计任务的组合：第一个任务的目的是通过分类指出目标的粗略位置，第二个任务则旨在估计精确的目标状态。</p>
<p>对于第二项任务，过去的跟踪器采取以下三种方式：以DCF和SiamFC为代表，采用粗暴的多尺度测试；以ATOM为代表，用梯度递增迭代地调整最初的目标框；以及SiamRPN家族——引入RPN思想。在对以上三种类型的方式进行分析和对比以后，本文总结出四点通用跟踪器的设计要点：</p>
<p>G1：Decomposition of classification and state estimation，分开进行分类和状态估计。</p>
<p>G2：Non-ambiguous scoring，无歧义分数，实际上是具有准确对应关系的分类置信分数。</p>
<p>G3：Prior knowledge-free，无先验知识。目标跟踪任务不应当拥有目标的尺度、大小等先验知识。</p>
<p>G4：Estimation quality assessment，对状态估计质量的独立评估。</p>
<h2 id="2-Main-Idea"><a href="#2-Main-Idea" class="headerlink" title="2. Main Idea"></a>2. Main Idea</h2><p>本文首先遵循G1原则做两个分支。</p>
<p><img src="/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/1.jpg" style="zoom:70%;"></p>
<p>分类部分与siamFC基本一致，采取位置作为训练样本——假如响应图中某个点对应的原图位置位于真实的目标范围中，则这个位置属于正样本。</p>
<p>对于回归分支，其设计思路也是针对每一个位置做回归——最后一层预测特征图上的每个位置$(x,y)$对于的输入图像位置$\left(\left\lfloor\frac{s}{2}\right\rfloor+ xs,\left\lfloor\frac{s}{2}\right\rfloor+ ys\right)$到地面真实边界框上下左右四个边的距离定义为一个4维的向量：</p>
<script type="math/tex; mode=display">
t 
∗
 =(l 
∗
 ,t 
∗
 ,r 
∗
 ,b 
∗
 )</script><p>则对该位置的回归任务可以形式化为：</p>
<script type="math/tex; mode=display">
l^{*}=\left(\left\lfloor\frac{s}{2}\right\rfloor+ xs\right)-x_0</script><script type="math/tex; mode=display">
t^{*}=\left(\left\lfloor\frac{s}{2}\right\rfloor+ ys\right)-y_0</script><script type="math/tex; mode=display">
r^{*}=x_1-\left(\left\lfloor\frac{s}{2}\right\rfloor+ xs\right)</script><script type="math/tex; mode=display">
b^{*}=y_1-\left(\left\lfloor\frac{s}{2}\right\rfloor+ ys\right)</script><p>其中$ (x_0,y_0)$和$ (x_1,y_1)$表示与$(x,y)对应的真实边界框$B^{*}$的左上角和右下角。</p>
<p>由于分类分数和回归操作都是针对“位置”这个概念的，也就是操作的区域都是基于该位置的周围一片区域，而不是与人为设定的anchor对应，所以满足非歧义性（G2）。加上没有预定义anchor，所以也没有先验知识的应用，符合（G3）。</p>
<p>接下来完成G4——对估计质量的独立评价：本文通过添加$1 × 1$卷积层来添加简单但有效的质量评估分支,该层输出反映子窗口中心周围的输入像素在跟踪问题中重要性高于其余部分的优先空间得分（Prior Spatial Score，PSS）：</p>
<script type="math/tex; mode=display">
PSS^{*}=\sqrt{\frac {min(l^{*},r^{*})}{max(l^{*},r^{*})}× \frac {min(t^{*},b^{*})}{max(t^{*},b^{*})}}</script><p>通过将PSS与相应的预测分类分数相乘来产生用于最终框选择的分数。这样，远离物体中心的点的权重就会大大下降，从而提高了跟踪精度。</p>
<h2 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h2><h3 id="3-1-From-SiamFC-towards-SiamFC"><a href="#3-1-From-SiamFC-towards-SiamFC" class="headerlink" title="3.1 From SiamFC towards SiamFC++"></a>3.1 From SiamFC towards SiamFC++</h3><p><img src="/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/2.jpg"></p>
<h3 id="3-2-Results-on-Several-Benchmarks"><a href="#3-2-Results-on-Several-Benchmarks" class="headerlink" title="3.2 Results on Several Benchmarks"></a>3.2 Results on Several Benchmarks</h3><p><img src="/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/3.jpg" style="zoom:80%;"></p>
<h3 id="3-3-Comparison-with-Trackers-that-Do-not-Apply-Our-Guidelines"><a href="#3-3-Comparison-with-Trackers-that-Do-not-Apply-Our-Guidelines" class="headerlink" title="3.3 Comparison with Trackers that Do not Apply Our Guidelines"></a>3.3 Comparison with Trackers that Do not Apply Our Guidelines</h3><p><img src="/2020/10/26/SiamFC-Towards-Robust-and-Accurate-Visual-Tracking-with-Target-Estimation-Guidelines/4.jpg" style="zoom:80%;"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/" itemprop="url">Self-Supervised Learning of Depth and Motion Under Photometric Inconsistency</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-09-22T19:00:00+08:00">
                2020-09-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在自监督单目深度估计任务中，文章提出了一种改进的框架，通过增加几何约束和尺度一致性约束，解决动态场景下光度不一致等问题，并增强时间图像序列中的尺度一致性，提升了单目深度和相机自运动估计的结果。</p>
<h2 id="1-Previous-work"><a href="#1-Previous-work" class="headerlink" title="1. Previous work"></a>1. Previous work</h2><p>单目深度估计是指通过机器人的单一摄像头获得的一帧或多帧图像来获取深度信息和机器人姿态的方法。在即使定位与地图构建（SLAM）和视觉里程计（VO）中广泛应用。传统的深度估计方法根据图像像素的特征点进行匹配，受噪声影响误差较大，2017年，Google在CVPR上发表论文Unsupervised Learning of Depth and Ego-motion from Video，提出了自监督学习框架，可以对连续的视频序列做单目深度和相机运动的估计任务。</p>
<script type="math/tex; mode=display">
p_s \sim K_s[R_{t\to s}|t_{t\to s}]D_t(p_t)K^{-1}_tp_t</script><p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/1.png" alt="1" style="zoom:50%;"></p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/2.png" alt="2" style="zoom:50%;"></p>
<p>这样的估计方法使用光度误差做自监督，存在一定的局限性：</p>
<ul>
<li>场景中存在移动物体、非漫反射表面和遮挡时，光度误差损失函数不适用</li>
<li>在单目场景下，单张物体深度估计结果是基于单张图片的相对深度，在连续多帧的估计结果中存在尺度不一致问题</li>
</ul>
<h2 id="2-Main-Idea"><a href="#2-Main-Idea" class="headerlink" title="2. Main Idea"></a>2. Main Idea</h2><ul>
<li><p>沿用原有的框架和光度一致性损失进行深度和姿态的无监督训练</p>
</li>
<li><p>利用相邻图像的稀疏特征匹配和对极几何约束，增强图像帧间的几何一致性</p>
</li>
<li><p>在相邻图像间增加深度一致性约束，减少深度图像估计结果中的噪声</p>
</li>
</ul>
<script type="math/tex; mode=display">
L_{total}=\alpha L_{pixel}+(1-\alpha)L_{SSIM}+\beta L_{smooth}+\gamma_1L{epi}+\gamma_2L_{reproj}+\mu_1L_{depth}+\mu_2L_{multi}</script><h2 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3. Approach"></a>3. Approach</h2><p>本论文利用了自监督单目深度估计的基本框架，并在此基础上进行了改进，在更复杂的场景下优化单目深度估计结果。框架由三部分构成，分别是深度和位姿估计网络（光度一致性误差）、对极几何一致性约束模块和深度一致性约束模块。</p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/3.png" alt="3"></p>
<h3 id="3-1-Photometric-consistency"><a href="#3-1-Photometric-consistency" class="headerlink" title="3.1 Photometric consistency"></a>3.1 Photometric consistency</h3><p>给定$N$帧连续的单目图像，无监督的深度和自运动估计问题在同时估计目标（中间帧）图像的深度图$D_t$和到$N-1$个源图像的相对姿势$T_{t \to s}=[R_{T \to S}|t_{t \to s}] \in SE(3)$。使用depth CNN和poseCNN进行训练。帧间重建的对应公式为：</p>
<script type="math/tex; mode=display">
p_s \sim K_s[R_{t\to s}|t_{t\to s}]D_t(p_t)K^{-1}_tp_t</script><p>利用帧间相机运动实现源图像（source）到目标图像（target）的重建，计算损失：</p>
<script type="math/tex; mode=display">
L_{pixel}=\frac {1}{|M|}\sum_{\forall p_t \in M}|\hat I^{(s)}_t(p_t|D_t,T_{t \to s})-I_t(p_t)|</script><p>在像素损失（pixel loss）的基础上增加结构相似性损失（SSIM loss）和边缘平滑损失（edge loss），光度一致性损失的计算公式如下：</p>
<script type="math/tex; mode=display">
L_{baseline}=\alpha L_{pixel}+(1-\alpha)L_{SSIM}+\beta L_{smooth}</script><h3 id="3-2-Epipolar-geometric-consistency"><a href="#3-2-Epipolar-geometric-consistency" class="headerlink" title="3.2 Epipolar geometric consistency"></a>3.2 Epipolar geometric consistency</h3><p>上述重建公式需要满足几个假设：</p>
<ul>
<li>建模场景是静态的，没有移动的对象</li>
<li>场景中的表面是朗伯型的</li>
<li>相邻视图之间不存在遮挡</li>
</ul>
<p>由于现实中的绝大多数场景会违背这些假设，所以使用光度一致性损失进行深度估计的结果存在一定的误差。为此，本文提出了一种通过将间接法几何信息注入直接学习的框架来解决此问题的新颖方法。与依赖于密集光度一致性的直接方法不同，视觉SLAM的间接方法基于稀疏的局部描述符，例如SIFT 和ORB 等。局部不变性受比例和光度变化的影响较小，且可以隐式地嵌入到学习框架中。</p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/5.png" alt="5" style="zoom: 50%;"></p>
<h4 id="3-2-1-Symmetric-epipolar-error"><a href="#3-2-1-Symmetric-epipolar-error" class="headerlink" title="3.2.1 Symmetric epipolar error"></a>3.2.1 Symmetric epipolar error</h4><p>对极几何约束：</p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/4.png" alt="4" style="zoom: 25%;"></p>
<script type="math/tex; mode=display">
p_2^tK^{-T}t\times RK^{-1}p_1=0</script><p>令本质矩阵$E=t \times R$，$x_1=K^{-1}p_1$，$x_2=K^{-1}p_2$，则对极约束可以化简为：</p>
<script type="math/tex; mode=display">
x_2^TEx_1=0</script><p>在相机针孔模型中，目标图像和源图像之间的特征匹配$S_{t \harr s}={\{}p \harr p^{‘}{\}}$满足对极约束，其中$p$和$p^{‘}$是校准后的图像坐标。利用对极约束，对于相邻两帧图像中多对匹配的特征点$p$ ，$p^{‘}$，计算<strong>symmetric epipolar error</strong>：</p>
<script type="math/tex; mode=display">
L_{epi}(S|R,t)=\sum_{\forall (p,p^{'}) \in S}(\frac {p^{'T}Ep}{\sqrt{(Ep)^2_{(1)}+(Ep)^2_{(2)}}} + \frac {p^{T}Ep^{'}}{\sqrt {(Ep^{'})^2_{(1)}+(Ep^{'})^2_{(2)}}})</script><h4 id="3-2-2-Re-projection-error"><a href="#3-2-2-Re-projection-error" class="headerlink" title="3.2.2 Re-projection error"></a>3.2.2 Re-projection error</h4><p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/6.png" alt="6" style="zoom: 25%;"></p>
<p>为了用特征匹配进行深度估计结果的优化，可使用估计的深度在一个图像中反投影2D特征以计算3D轨迹，然后将3D轨迹重新投影到另一幅图像以计算重新投影误差。由于特征点$p$的坐标不是整数，因此使用$\hat D_t(p)$在目标深度图像上进行双线性采样。</p>
<script type="math/tex; mode=display">
L_{reproj}(S|R,t,D_t)=\sum _{\forall p \harr p^{'} \in S}||[R|t]\hat D_t(p)p-p^{'}||_2</script><p>设计卷积神经网络的几何误差，将所有匹配项的对极误差和重投影误差降至最低，可模仿传统SLAM中的非线性姿态估计策略。</p>
<h3 id="3-3-Consistent-Depth-Estimation"><a href="#3-3-Consistent-Depth-Estimation" class="headerlink" title="3.3 Consistent Depth Estimation"></a>3.3 Consistent Depth Estimation</h3><p>在深度估计模块中，损失函数从源帧到目标帧成对进行计算，即使位姿估计网络一次输出$N-1$个相对姿势，也无法确定这些相对姿势是否按相同比例对齐。本文提出了运动一致深度估计公式来解决此问题。</p>
<h4 id="3-3-1-Forward-backward-consistency"><a href="#3-3-1-Forward-backward-consistency" class="headerlink" title="3.3.1 Forward-backward consistency"></a>3.3.1 Forward-backward consistency</h4><p>本文提出了单目图像的前后一致性。除了双线性采样像素值外，还估计出当前帧的前向和后向图像的深度图。这个过程产生了两个合成的深度图，它们可以用来约束目标图像深度图$\widetilde D^{(s)}_t$的估计。由于在单目估计中深度仅按比例确定，因此在限制深度之前须对深度按比例进行归一化对齐。前后一致性损失计算公式为：</p>
<script type="math/tex; mode=display">
L_{depth}=\frac{1}{|M|}\sum _{\forall p\in M}|\frac{mean(D_t·M)}{mean(\widetilde D^{(s)}_t·M)}·\widetilde D^{(s)}_t(p)-D_t(p)|</script><h4 id="3-3-2-Multi-view-consistency"><a href="#3-3-2-Multi-view-consistency" class="headerlink" title="3.3.2 Multi-view consistency"></a>3.3.2 Multi-view consistency</h4><p>上述损失函数的设计都是基于单帧进行深度估计，为了增强长视频序列的多帧尺度一致性，本文提出了多视角一致性损失，该损失以目标图像（中间帧图像）为尺度对齐的纽带，惩罚项计算了前向深度和后向深度的不一致损失。</p>
<p>形式上，给定连续图像$(I_1,I_2,I_3)$，$I_2$为目标图像，对应的深度估计结果为$(D_1,D_2,D_3)$，位姿估计结果为$(T_{2 \to 1},T_{2 \to 3})$，归一化深度图计算公式为$\overline D_1=s_{12}·D_1$，$I_1$到$I_3$的位姿变化为$T_{1 \to 3}=T_{2 \to 1}^{-1}·T_{2 \to 3}$。多视图损失将深度一致性项和光度一致性项最小化为：</p>
<script type="math/tex; mode=display">
L_{multi}=\alpha L_{pixel}(I_1,\widetilde I^{(3)}_1)+(1-\alpha)L_{SSIM}(I_1,\widetilde I^{(3)}_1)+\frac{1}{|M_{13}|}\sum_{\forall p\in M_{13}}|\overline D_1(p)-\overline D^{(3)}_1(p)|</script><p>$\widetilde I^{(3)}_1$和$\overline D^{(3)}_1$是给定$\overline D_3$ 和$T_{1 \to 3}$之后通过计算得到的重建图像。$L_{multi}$更优于成对损失$L_{pixel}$，$L_{SSIM}$，$L_{epi}$和$L_{depth}$，它利用了链式姿态计算，将两个相对姿势调整到相同的比例，通过对齐多对连续图像来促进增量定位，优化了单目SLAM的结果。</p>
<h2 id="4-Experiment"><a href="#4-Experiment" class="headerlink" title="4. Experiment"></a>4. Experiment</h2><h3 id="4-1-Depth-Estimation"><a href="#4-1-Depth-Estimation" class="headerlink" title="4.1 Depth Estimation"></a>4.1 Depth Estimation</h3><p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/7.png" alt="7"></p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/8.png" alt="8"></p>
<h3 id="4-2-Pose-Estimation"><a href="#4-2-Pose-Estimation" class="headerlink" title="4.2 Pose Estimation"></a>4.2 Pose Estimation</h3><p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/9.png" alt="9" style="zoom:33%;"></p>
<p><img src="/2020/09/22/Self-Supervised-Learning-of-Depth-and-Motion-Under-Photometric-Inconsistency/10.png" alt="10" style="zoom:30%;"></p>
<h2 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h2><p><a href="https://arxiv.org/abs/1909.09115v1" target="_blank" rel="noopener">https://arxiv.org/abs/1909.09115v1</a></p>
<p><a href="https://arxiv.org/abs/1704.07813" target="_blank" rel="noopener">https://arxiv.org/abs/1704.07813</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/20/Inductive-Representation-Learning-on-Large-Graphs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/20/Inductive-Representation-Learning-on-Large-Graphs/" itemprop="url">Inductive Representation Learning on Large Graphs</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-09-20T17:30:08+08:00">
                2020-09-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-问题定位"><a href="#1-问题定位" class="headerlink" title="1 问题定位"></a>1 问题定位</h2><p>在大规模graph上学到的节点<strong>低维embedding</strong>，在很多预测任务中非常有用，如内容推荐、节点分类等 。但是现在大多数方法都是transductive（直推式）学习， 不能直接泛化到未知节点。这些方法是在一个固定的graph上直接学习每个节点的embedding，但是大多情况graph是会演化的，当网络结构改变以及新节点的出现，直推式学习需要重新训练，很难落地在需要快速生成unseen节点embedding的机器学习系统上。本文<strong>提出inductive（归纳式）学习框架—GraphSAGE(Graph SAmple and aggreGatE)，通过训练多个聚合邻居节点特征的function，将GCN扩展成归纳学习任务，从而对unseen节点起到泛化作用</strong>。</p>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><p>大部分学习节点embedding的方法有以下三种：</p>
<p>一、基于因子分解的embedding生成方法：近年来有许多使用随机游走统计和基于矩阵分解来生成节点低维embedding的方法，如基于spectral clustering（谱聚类）的方法以及PageRank算法。因为这些embedding算法直接为单个节点训练节点embedding，所以它们本质上是transductive的（即不能泛化到unseen节点），而且需要expensive的额外训练(例如，重新通过随机梯度下降)来对新节点进行预测。</p>
<p>二、图上的监督学习：</p>
<p>除了节点嵌入方法之外，还有大量关于对图结构数据进行监督学习的paper。这包括各种基于核的方法，其中图的特征向量是从不同的graph kernel中派生出来的。本文在概念上受到了这些算法的启发。然而，前面的这些方法试图对整个图(或子图)进行分类，而这篇paper的重点是为单个节点生成有用的embedding。</p>
<p>三、图卷积网络：</p>
<p>近年来，人们提出了几种用于图学习的卷积神经网络结构。这些方法中的大多数不能推广到大规模的图，或者是为图分类而设计的。然而，本文的方法与Kipf等人引入的图卷积网络(GCN)密切相关。原来的GCN算法是为transductive设置下的半监督学习而设计的，该算法要求在训练过程中全图Laplacian矩阵是已知的，本文可以看作是GCN框架对inductive设置的扩展。</p>
<h2 id="3-文章工作"><a href="#3-文章工作" class="headerlink" title="3 文章工作"></a>3 文章工作</h2><p>本文提出GraphSAGE框架的核心是如何聚合节点邻居特征信息，本章先<strong>介绍GraphSAGE前向传播过程</strong>（生成节点embedding），<strong>不同的聚合函数</strong>设定；然后介绍<strong>无监督和有监督的损失函数</strong>以及<strong>参数学习。</strong></p>
<h3 id="3-1-前向传播"><a href="#3-1-前向传播" class="headerlink" title="3.1 前向传播"></a>3.1 前向传播</h3><p><strong>a. 可视化例子：</strong>下图是GraphSAGE 生成目标节点（红色）embededing并供下游任务预测的过程：</p>
<p><img src="/2020/09/20/Inductive-Representation-Learning-on-Large-Graphs/v2-7e94e024910274eee88ab3947fd3dff4_1440w.jpg" alt="image-20200924141919374"></p>
<ol>
<li>先对邻居随机采样，降低计算复杂度（图中一跳邻居采样数=3，二跳邻居采样数=5）</li>
<li>生成目标节点emebedding：先聚合2跳邻居特征，生成一跳邻居embedding，再聚合一跳邻居embedding，生成目标节点embedding，从而获得二跳邻居信息。</li>
<li>将embedding作为全连接层的输入，预测目标节点的标签。</li>
</ol>
<p><strong>b. 伪代码:</strong></p>
<p><img src="/2020/09/20/Inductive-Representation-Learning-on-Large-Graphs/image-20200924141947029.png" alt="image-20200924141947029"></p>
<p>4-5行是核心代码，介绍卷积层操作：聚合与节点v相连的邻居（采样）k-1层的embedding，得到第k层邻居聚合特征  $h^k_{N(v)}$，与节点v第k-1层embedding $h^{k-1}_v$拼接，并通过全连接层转换，得到节点v在第k层的embedding  $h^k_{v}$。</p>
<h3 id="3-2-聚合函数"><a href="#3-2-聚合函数" class="headerlink" title="3.2 聚合函数"></a><strong>3.2 聚合函数</strong></h3><p>伪代码第5行可以使用不同聚合函数，本小节介绍五种满足排序不变量的聚合函数：平均、GCN归纳式、LSTM、pooling聚合器。（因为邻居没有顺序，聚合函数需要满足排序不变量的特性，即输入顺序不会影响函数结果）</p>
<p><strong>a.平均聚合：</strong>先对邻居embedding中每个维度取平均，然后与目标节点embedding拼接后进行非线性转换。</p>
<script type="math/tex; mode=display">h^k_{N(v)} = mean({h^{k-1}_u,u\in N(v)})</script><script type="math/tex; mode=display">h^k_v = \sigma(W^k . CONCAT(h^{k-1}_v,h^k_{N(u)}))</script><p><strong>b. 归纳式聚合：</strong>直接对目标节点和所有邻居emebdding中每个维度取平均（替换伪代码中第5、6行），后再非线性转换：</p>
<script type="math/tex; mode=display">h^k_v = \sigma(W^k . mean(\{h^{k-1}_v\} \cup \{h^{k-1}_u,\forall u \in N(v)\}))</script><p><strong>c. LSTM聚合：</strong>LSTM函数不符合“排序不变量”的性质，需要先对邻居随机排序，然后将随机的邻居序列embedding  $\{x_t,t\in N(v)\}$作为LSTM输入。</p>
<p><strong>d. Pooling聚合器:</strong>先对每个邻居节点上一层embedding进行非线性转换（等价单个全连接层，每一维度代表在某方面的表示（如信用情况）），再按维度应用 max/mean pooling，捕获邻居集上在某方面的突出的／综合的表现 以此表示目标节点embedding。</p>
<script type="math/tex; mode=display">h^k_{N(v)} = max(\{\sigma(W_{pool}{h^k_{u_i}+b,\forall u_i\in N(v)})</script><script type="math/tex; mode=display">h^k_v = \sigma(W^k . CONCAT(h^{k-1}_v,h^k_{N(u)}))</script><h3 id="3-3-无监督和有监督损失设定"><a href="#3-3-无监督和有监督损失设定" class="headerlink" title="3.3 无监督和有监督损失设定"></a><strong>3.3 无监督和有监督损失设定</strong></h3><p>损失函数根据具体应用情况，可以使用<strong>基于图的无监督损失</strong>和<strong>有监督损失</strong>。</p>
<p><strong>a. 基于图的无监督损失：</strong>希望节点u与“邻居”v的embedding也相似（对应公式第一项），而与“没有交集”的节点$v_n$不相似（对应公式第二项)。</p>
<script type="math/tex; mode=display">J_G(z_u) = -log(\sigma(z^T_uz_v)) - Q.E_{v_n \sim P_n(v)}log(\sigma(-z^T_uz_{v_n}))</script><ul>
<li>$z_u$为节点u通过GraphSAGE生成的embedding。</li>
<li>节点v是节点u随机游走访达“邻居”。</li>
<li>$v_n \sim P_n(u)$表示负采样：节点 $v_n$是从节点u的负采样分布 $P_n$ 采样的，Q为采样样本数。</li>
<li>embedding之间相似度通过向量点积计算得到</li>
</ul>
<p><strong>b. 有监督损失：</strong>无监督损失函数的设定来学习节点embedding 可以供下游多个任务使用，若仅使用在特定某个任务上，则可以替代上述损失函数符合特定任务目标，如交叉熵。</p>
<h3 id="3-4-参数学习"><a href="#3-4-参数学习" class="headerlink" title="3.4 参数学习"></a>3.4 参数学习</h3><p>通过前向传播得到节点u的embedding  $z_u$ ,然后梯度下降（实现使用Adam优化器） <strong>进行反向</strong>传播优化参数 $W^k$ 和聚合函数内参数。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="COOLA-LAB">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="COOLA-LAB">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/" itemprop="url">Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-09-13T19:00:00+08:00">
                2020-09-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%AF%8F%E5%91%A8%E4%B8%80%E4%BC%9A/" itemprop="url" rel="index">
                    <span itemprop="name">每周一会</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这篇论文提出了一种叫做“动态风险密度”（Dynamic Risk Density）的方法，用于解决在没有目标检测的杂乱环境下进行导航的问题。</p>
<h2 id="1-Previous-work"><a href="#1-Previous-work" class="headerlink" title="1. Previous work"></a>1. Previous work</h2><p><img src="/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/1.jpg" style="zoom:33%;"></p>
<p>在 Navigating Congested Environments with Risk Level Sets 这篇论文中，作者提出了占据风险代价函数：</p>
<script type="math/tex; mode=display">H(q,x,\dot{x})=\sum^{n}_{i=1}{\frac{\exp(-(q-x_i)^T\Omega(q-x_i))}{1+\exp(-\alpha\dot{x_i}^T(q-x_i))}},\Omega=diag\{\frac{1}{\sigma^2_x},\frac{1}{\sigma^2_y}\} \tag{1}</script><p>其中，</p>
<ul>
<li>$q$：表示二维平面内的任意一个点；</li>
<li>$x$：表示二维平面内所有障碍物的位置，例如图(a)中的四个点；</li>
<li>$\dot{x}$：表示二维平面内所有障碍物的速度，例如图(a)中四个点上的箭头。</li>
</ul>
<p>通过计算 $H$，我们可以得到平面内每个点的占据风险代价，可以将其看成是该点在下一个时刻会出现障碍物的概率。在导航的过程中，为了不发生碰撞，自然要避免经过 $H$ 值大的点。</p>
<p>$H$ 是由一个高斯峰 $\exp(-(q-x_i)^T\Omega(q-x_i))$ 乘上一个 logistic 函数 $\frac{1}{1+\exp(-\alpha\dot{x_i}^T(q-x_i))}$ 构成。很显然，离障碍物越近的点 $H$ 值会越大，这由高斯峰来进行描述，logistic 函数则是对这个高斯峰在速度方向上进行了偏移，如图(b)所示。</p>
<p>在导航的过程中，给定一个阈值 $H_p$，只要确保只在 $H\leq H_p$ 的区域内行动就能避免发生碰撞。</p>
<h2 id="2-Main-Idea"><a href="#2-Main-Idea" class="headerlink" title="2. Main Idea"></a>2. Main Idea</h2><p>在 Previous work 提到的方法中，我们假设已知了环境中所有障碍物的位置和速度，但在现实场景下，这往往是很难得到的。因此，在 Dynamic Risk Density for Autonomous Navigation in Cluttered Environments without Object Detection 这篇论文中，作者对其进行了改进，分别用“占据密度”(occupancy density)和“速度场”(velocity flow field)代替了障碍物的位置和速度。提出了动态风险密度：</p>
<script type="math/tex; mode=display">H_\rho(q,t,\rho,V)=\frac{\rho(q,t)}{1+\exp(\alpha\nabla\rho(q,t)\cdot V(q,t))} \tag{2}</script><p>其中，</p>
<ul>
<li>$\rho$：表示占据密度；</li>
<li>$V$：表示速度场。</li>
</ul>
<p>$H_\rho$ 和 $H$ 的意义类似。</p>
<p><img src="/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/2.jpg" style="zoom:33%;"></p>
<p>通过仿真可以看出，由这两种方法得到的轮廓线非常相似（左图是计算 $H$ 值得到的，右图是计算 $H_\rho$ 值得到的）。</p>
<h2 id="3-Approach"><a href="#3-Approach" class="headerlink" title="3. Approach"></a>3. Approach</h2><p>在这篇论文中，通过使用一个二维激光扫描仪来构建环境的占据网格而得到占据密度。</p>
<p>对于如何计算速度场，论文中提出了两种方法，分别是基于<strong>聚类</strong>的方法和基于<strong>密度流</strong>的方法。</p>
<h3 id="3-1-Velocity-Field-Estimation-from-Density-Flow"><a href="#3-1-Velocity-Field-Estimation-from-Density-Flow" class="headerlink" title="3.1 Velocity Field Estimation from Density Flow"></a>3.1 Velocity Field Estimation from Density Flow</h3><p>基于聚类的方法，使用 k-means 算法对占据网格进行聚类，并计算聚类中心的速度，再通过 Voronoi 分布将聚类中心的速度映射到所有的点上。</p>
<p><img src="/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/3.jpg" style="zoom:33%;"></p>
<h3 id="3-2-Velocity-Field-Estimation-from-Density-Flow"><a href="#3-2-Velocity-Field-Estimation-from-Density-Flow" class="headerlink" title="3.2 Velocity Field Estimation from Density Flow"></a>3.2 Velocity Field Estimation from Density Flow</h3><p>基于密度流的方法与计算机视觉中的光流法类似。</p>
<p>在这里引入了两个假设：</p>
<ol>
<li>密度不变性，即同一个点在经过 $\Delta t$ 时间移动了 $\Delta x$， $\Delta y$ 之后，密度没有发生改变：</li>
</ol>
<script type="math/tex; mode=display">\rho^t(x,y)=\rho(x,y,t)=\rho(x+\Delta x,y+\Delta y,t+\Delta t) \tag{3}</script><ol>
<li>对于 $\rho(x+\Delta x,y+\Delta y,t+\Delta t)$ 可以进行一阶泰勒展开：</li>
</ol>
<script type="math/tex; mode=display">\rho(x+\Delta x,y+\Delta y,t+\Delta t)=\rho(x,y,t)+\frac{\partial\rho}{\partial x}\Delta x+\frac{\partial\rho}{\partial y}\Delta y+\frac{\partial\rho}{\partial t}\Delta t+H.O.T. \tag{4}</script><p>结合(3)(4)可以得到：</p>
<script type="math/tex; mode=display">\frac{\partial\rho}{\partial x}\frac{\Delta x}{\Delta t} +\frac{\partial\rho}{\partial y}\frac{\Delta y}{\Delta t}+\frac{\partial\rho}{\partial t}=0 \tag{5}</script><p>对(5)进行变量替换：</p>
<script type="math/tex; mode=display">u=\frac{\Delta x}{\Delta t},v=\frac{\Delta y}{\Delta t}</script><script type="math/tex; mode=display">I_x=\frac{\partial\rho}{\partial x},I_y=\frac{\partial\rho}{\partial y},I_t=\frac{\partial\rho}{\partial t}</script><p>化简可得：</p>
<script type="math/tex; mode=display">\left[\begin{matrix} I_x&I_y \end{matrix}\right] \left[\begin{matrix} u\\v \end{matrix}\right] = -I_t \tag{6}</script><p>这是一个二元一次方程，无法进行求解，因此，必须引入额外的约束来计算 u,v。我们假设某一个窗口内的点具有相同的运动。</p>
<p>考虑一个大小为 $w*w$ 大小的窗口，它含有 $w^2$ 数量的像素。由于该窗口内像素具有 同样的运动，因此我们共有 $w^2$ 个方程： </p>
<script type="math/tex; mode=display">\left[\begin{matrix} I_x&I_y \end{matrix}\right]_k \left[\begin{matrix} u\\v \end{matrix}\right] = -I_{tk}, k=1,2,...,w^2 \tag{7}</script><p>记：</p>
<script type="math/tex; mode=display">A=\left[\begin{matrix}[I_x,I_y]_1\\ \vdots\\ [I_x,I_y]_k\end{matrix}\right],b=\left[\begin{matrix}I_{t1}\\ \vdots\\ I_{tk}\end{matrix}\right]</script><p>于是整个方程为：</p>
<script type="math/tex; mode=display">A\left[\begin{matrix}u\\v\end{matrix}\right]=-b \tag{8}</script><p>利用最小二乘法可以求得：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}u\\v\end{matrix}\right]^*=-(A^TA)^{-1}A^Tb \tag{9}</script><h3 id="3-3-Navigation-Algorithm"><a href="#3-3-Navigation-Algorithm" class="headerlink" title="3.3 Navigation Algorithm"></a>3.3 Navigation Algorithm</h3><p><img src="/2020/09/13/Dynamic-Risk-Density-for-Autonomous-Navigation-in-Cluttered-Environments-without-Object-Detection/4.jpg" style="zoom:33%;"></p>
<p>Experiment：<a href="https://www.youtube.com/watch?v=uXry23LxpWw" target="_blank" rel="noopener">https://www.youtube.com/watch?v=uXry23LxpWw</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">&lt;i class&#x3D;&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">COOLA-LAB</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">COOLA-LAB</span>

  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>




  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>



-->

        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
